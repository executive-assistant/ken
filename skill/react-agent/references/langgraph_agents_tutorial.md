# LangGraph Agents Tutorial - DataCamp

Source: https://www.datacamp.com/tutorial/langgraph-agents

## LangGraph Fundamentals

### State

The state is a shared memory object that flows through the graph. It stores all the relevant information such as messages, variables, intermediate results, and decision history. LangGraph manages the state automatically.

Supporting features:
- Checkpointing
- Thread-local memory
- Cross-session persistence

### Node

A node is a single functional unit in the workflow. It can perform:
- Invoking a large language model (LLM)
- Calling a tool or API
- Running a custom Python function
- Routing logic or branching decisions

Each node takes in the current state and returns an updated state.

### Edges and Conditional Edges

Edges define the transitions between nodes. They can support:
- Static connections (for linear progression)
- Cyclical paths (for iterative behaviors)
- Dynamic branching (based on state conditions - created through Conditional Edges)

### Graph and StateGraph

A graph in LangGraph defines the structure of the agentic workflow. The StateGraph is a specialized graph that maintains and updates a shared state throughout execution.

### Tool and ToolNode

A tool is any external or internal function an agent can call. There are two types:
- **In-built Tools**: Pre-made tools from Langchain
- **Custom Tools**: Tools you create yourself using the `@tool` decorator

A ToolNode is a dedicated node type for executing tools within the graph.

### Message Types

- **HumanMessage**: Represents input from a user
- **AIMessage**: Represents the responses generated by the LLM
- **SystemMessage**: Provides context or behavior setup instructions to the LLM
- **ToolMessage**: Encapsulates the output from a tool
- **RemoveMessage**: Used to programmatically delete messages from the state
- **BaseMessage**: The parent class for all message types

## Single-Agent Workflow

```python
from typing import TypedDict, List
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from dotenv import load_dotenv

load_dotenv()

# Creation of the state using a Typed Dictionary
class AgentState(TypedDict):
    messages: List[HumanMessage]

llm = ChatOpenAI(model="gpt-4o")

# This is an action - the underlying function of our node
def process(state: AgentState) -> AgentState:
    response = llm.invoke(state["messages"])
    print(f"\nAI: {response.content}")
    return state

graph = StateGraph(AgentState)
graph.add_node("process_node", process)
graph.add_edge(START, "process_node")
graph.add_edge("process_node", END)
agent = graph.compile()
```

### Visualizing the Graph

```python
from IPython.display import Image, display
display(Image(agent.get_graph().draw_mermaid_png()))
```

## ReAct Agents

ReAct Agents (Reasoning and Acting Agents) are extremely common in industry. LangGraph has an inbuilt method to create such Agents.

```python
from langgraph.prebuilt import create_react_agent
from langchain_google_community import GmailToolkit

tools = [GmailToolkit()]
llm = ChatOllama(model="qwen2.5:latest")

agent = create_react_agent(
    model = llm,
    tools = tools,
    name = "email_agent",
    prompt = "You are my AI assistant that has access to certain tools. Use the tools to help me with my tasks.",
)
```

### Creating Custom Tools

```python
@tool
def send_email(email_address: str, email_content: str) -> str:
    """ Sends an email to a specified recipient with the given content.

    Args:
        email_address (str): The recipient's email address (e.g., 'example@example.com')
        email_content (str): The body of the email message to be sent

    Returns:
        str: A confirmation message indicating success or failure

    Example:
        >>> send_email('john.doe@example.com', 'Hello John, just checking in!')
        'Email successfully sent to john.doe@example.com'
    """
    # Tool Logic goes here
    return "Done!"
```

Key components for custom tools:
1. **Decorator**: `@tool` tells LangGraph this is a specialized function
2. **Docstring**: Provides context to the LLM about what the tool does

## Memory Management in LangGraph

### External Checkpoint Stores

Popular external storage options:
- SQLite
- PostgreSQL
- Amazon S3
- Azure Blob Storage
- Google Cloud Storage
- Mem0

```python
from langgraph.checkpoint.sqlite import SqliteSaver

memory = SqliteSaver.from_conn_string(":memory:")
graph = graph_builder.compile(checkpointer=memory)
```

### Short-term Memory

```python
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph

checkpointer = InMemorySaver()
builder = StateGraph(...)
graph = builder.compile(checkpointer=checkpointer)

agent_graph.invoke(
    {"messages": [{"role": "user", "content": "What's the weather today?"}]},
    {"configurable": {"thread_id": "session_42"}},
)
```

### Long-term Memory

```python
from langgraph.store.memory import InMemoryStore
from langgraph.graph import StateGraph

long_term_store = InMemoryStore()
builder = StateGraph(...)
agent = builder.compile(store=long_term_store)
```

### Trimming

```python
from langchain_core.messages.utils import trim_messages, count_tokens_approximately

trimmed = trim_messages(
    messages=state["messages"],
    strategy="first",
    token_counter=count_tokens_approximately,
    max_tokens=150
)
```

### Summarization-based Pruning

```python
from langmem.short_term import SummarizationNode
from langchain_core.messages.utils import count_tokens_approximately

summary_node = SummarizationNode(
    model=summary_llm,
    max_tokens=300,
    max_tokens_before_summary=150,
    max_summary_tokens=150,
    token_counter=count_tokens_approximately
)
```

### Selective Deletion

```python
from langchain_core.messages import RemoveMessage

def clean_state(state):
    # Remove all tool-related messages
    to_remove = [RemoveMessage(id=msg.id) for msg in state["messages"] if msg.role == "tool"]
    return {"messages": to_remove}
```

Reset entire history:

```python
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langchain_core.messages import RemoveMessage

def reset_history(state):
    # Remove entire conversation history
    return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}
```
